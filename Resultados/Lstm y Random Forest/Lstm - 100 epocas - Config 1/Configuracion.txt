100 epocas

  lstm_pitch = Sequential([  # Usamos un modelo secuencial para construir la red paso a paso
        Input(shape=(longitud_secuencia, 1)),  # Capa de entrada, espera una secuencia de longitud `longitud_secuencia` y 1 característica por paso temporal
        LSTM(256, return_sequences=True),  # Primera capa LSTM con 256 unidades; devuelve secuencias para que la siguiente capa LSTM pueda procesarlas
        Dropout(0.3),  # Capa Dropout para reducir el sobreajuste; apaga aleatoriamente el 30% de las unidades durante el entrenamiento
        LSTM(256),  # Segunda capa LSTM con 256 unidades; esta vez no devuelve secuencias (última capa recurrente)
        Dense(256),  # Capa completamente conectada (densa) con 256 unidades para procesar características
        Dropout(0.3),  # Otra capa Dropout para mejorar la generalización
        Dense(len(notasyacordes)),  # Capa de salida con tantas neuronas como notas/acordes únicos en el vocabulario
        Activation('softmax')  # Función de activación softmax para generar probabilidades para cada posible nota/acorde
    ])
    
    # Compilar el modelo
    lstm_pitch.compile(
        loss='categorical_crossentropy',  # Usamos la pérdida de entropía cruzada categórica para problemas de clasificación multiclase
        optimizer='adam'  # El optimizador Adam, que combina las ventajas de AdaGrad y RMSProp, ajusta dinámicamente las tasas de aprendizaje
    )
	
	  
    rf_velocity = RandomForestClassifier(n_estimators=100)
    rf_duration = RandomForestClassifier(n_estimators=100)
 
 
 100 epocas
 
 Secuencias de 20